{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'heartdisease'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "heartdisease = pd.read_sql_query('select * from heartdisease',con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the number of rows divides evenly into four samples.\n",
    "rows = heartdisease.shape[0] - heartdisease.shape[0] % 2\n",
    "df = heartdisease.iloc[:rows, :]\n",
    "\n",
    "# Break into a set of features and a variable for the known outcome.\n",
    "X = df.iloc[:, :13]\n",
    "y = df.iloc[:, 13]\n",
    "\n",
    "# Replace some random string values.\n",
    "X = X.replace(to_replace='?', value=0)\n",
    "\n",
    "# Binarize y so that 1 means heart disease diagnosis and 0 means no diagnosis.\n",
    "y = np.where(y > 0, 0, 1)\n",
    "\n",
    "# Normalize\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the two-feature PCA for graphing purposes.\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apply GMM to the heart disease data by setting n_components=2. Get ARI and silhoutte scores for your solution and compare it with those of the k-means and hierarchical clustering solutions that you implemented in the assignments of the previous checkpoints. Which algorithm does perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=123)\n",
    "\n",
    "clusters = gmm_cluster.fit_predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.18230716541111341\n",
      "The silhoutte score of the GMM solution: 0.13560123273712887\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k means solution is still performing the best with an ARI score of 0.44 and silhouette score of 0.17. The average linkage method had the best score for agglomerative clustering with an ARI of 0.29 and silhouette of 0.15. The GMM scores were the worst so far with scores of 0.18 and 0.14. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. GMM implementation of scikit-learn has a parameter called covariance_type. This parameter determines the type of covariance parameters to use. Specifically, there are four types you can specify:\n",
    "\n",
    "full: This is the default. Each component has its own general covariance matrix.\n",
    "\n",
    "tied: All components share the same general covariance matrix.\n",
    "\n",
    "diag: Each component has its own diagonal covariance matrix.\n",
    "\n",
    "spherical: Each component has its own single variance.\n",
    "\n",
    "Try all of these. Which one does perform better in terms of ARI and silhouette scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.18230716541111341\n",
      "The silhoutte score of the GMM solution: 0.13560123273712887\n"
     ]
    }
   ],
   "source": [
    "# tied covariance type\n",
    "gmm_cluster = GaussianMixture(n_components=2, covariance_type = 'tied', random_state=123)\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.18230716541111341\n",
      "The silhoutte score of the GMM solution: 0.13560123273712887\n"
     ]
    }
   ],
   "source": [
    "# diag covariance type\n",
    "gmm_cluster = GaussianMixture(n_components=2, covariance_type = 'diag', random_state=123)\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.2060175349560907\n",
      "The silhoutte score of the GMM solution: 0.12345483213377387\n"
     ]
    }
   ],
   "source": [
    "# spherical covariance type\n",
    "gmm_cluster = GaussianMixture(n_components=2, covariance_type = 'spherical', random_state=123)\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GMM using the spherical covariance parameter had the best ARI score at 0.21, however it also had the worst silhoutte score at 0.12. All the other covariance parameters achieved the same ARI and silhoutte scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
