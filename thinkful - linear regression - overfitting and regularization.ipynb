{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>mszoning</th>\n",
       "      <th>lotfrontage</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lotshape</th>\n",
       "      <th>landcontour</th>\n",
       "      <th>utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>poolqc</th>\n",
       "      <th>fence</th>\n",
       "      <th>miscfeature</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saletype</th>\n",
       "      <th>salecondition</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mssubclass mszoning  lotfrontage  lotarea street alley lotshape  \\\n",
       "0   1          60       RL         65.0     8450   Pave  None      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave  None      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave  None      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave  None      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave  None      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave  None      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave  None      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave  None      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave  None      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave  None      Reg   \n",
       "\n",
       "  landcontour utilities  ... poolarea poolqc  fence miscfeature miscval  \\\n",
       "0         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "1         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "2         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "3         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "4         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "5         Lvl    AllPub  ...        0   None  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "7         Lvl    AllPub  ...        0   None   None        Shed     350   \n",
       "8         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "9         Lvl    AllPub  ...        0   None   None        None       0   \n",
       "\n",
       "  mosold yrsold  saletype  salecondition  saleprice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "hp = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "hp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "#add winsorized variables to original dataframe\n",
    "hp['wins_saleprice'] = winsorize(hp['saleprice'], (0, 0.05))\n",
    "hp['wins_grlivarea'] = winsorize(hp['grlivarea'], (0, 0.05))\n",
    "hp['wins_garagearea'] = winsorize(hp['garagearea'], (0, 0.05))\n",
    "hp['wins_totalbsmtsf'] = winsorize(hp['totalbsmtsf'], (0, 0.05))\n",
    "hp['wins_firstflrsf'] = winsorize(hp['firstflrsf'], (0, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp[\"dummies_utilities\"] = pd.get_dummies(hp.utilities, drop_first=True)\n",
    "hp[\"dummies_centralair\"] = pd.get_dummies(hp.centralair, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in training set is: 0.8358338354106741\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8403868119284769\n",
      "Mean absolute error of the prediction is: 19642.677645928008\n",
      "Mean squared error of the prediction is: 684598096.0648007\n",
      "Root mean squared error of the prediction is: 26164.825550054804\n",
      "Mean absolute percentage error of the prediction is: 13.01981648871598\n"
     ]
    }
   ],
   "source": [
    "## OLS model\n",
    "\n",
    "Y = hp['wins_saleprice']\n",
    " \n",
    "X = hp[['overallqual', 'garagecars', 'totrmsabvgrd', 'yearbuilt', 'wins_totalbsmtsf', 'wins_grlivarea','wins_garagearea', 'dummies_centralair']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)\n",
    "\n",
    "lrm = LinearRegression()\n",
    "\n",
    "lrm.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds_train = lrm.predict(X_train)\n",
    "Y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model in training set is: {}\".format(lrm.score(X_train, Y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lrm.score(X_test, Y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(Y_test, Y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(Y_test, Y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(Y_test, Y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((Y_test - Y_preds_test) / Y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linear regression models and set alphas\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1.0\n",
      "R-squared of the model on the training set is: 0.8358334449749661\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.8404475576080839\n",
      "Mean absolute error of the prediction is: 19637.06296561745\n",
      "Mean squared error of the prediction is: 684337551.3246977\n",
      "Root mean squared error of the prediction is: 26159.846164010556\n",
      "Mean absolute percentage error of the prediction is: 13.015752906960923\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridgeregr = RidgeCV(alphas = alphas, cv =5) \n",
    "ridgeregr.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds_train = ridgeregr.predict(X_train)\n",
    "Y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(ridgeregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(ridgeregr.score(X_train, Y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(ridgeregr.score(X_test, Y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(Y_test, Y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(Y_test, Y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(Y_test, Y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((Y_test - Y_preds_test) / Y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1e-10\n",
      "R-squared of the model on the training set is: 0.835833835410674\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.8403868119284774\n",
      "Mean absolute error of the prediction is: 19642.677645927943\n",
      "Mean squared error of the prediction is: 684598096.0647985\n",
      "Root mean squared error of the prediction is: 26164.82555005476\n",
      "Mean absolute percentage error of the prediction is: 13.019816488715907\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lassoregr = LassoCV(alphas = alphas, cv = 5) \n",
    "lassoregr.fit(X_train, Y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "Y_preds_train = lassoregr.predict(X_train)\n",
    "Y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lassoregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lassoregr.score(X_train, Y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lassoregr.score(X_test, Y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(Y_test, Y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(Y_test, Y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(Y_test, Y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((Y_test - Y_preds_test) / Y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.01\n",
      "R-squared of the model on the training set is: 0.835822121692912\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.8407135897877277\n",
      "Mean absolute error of the prediction is: 19612.77488142502\n",
      "Mean squared error of the prediction is: 683196510.7510669\n",
      "Root mean squared error of the prediction is: 26138.028057813906\n",
      "Mean absolute percentage error of the prediction is: 12.998357666078967\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet regression\n",
    "elasticregr = ElasticNetCV(alphas=alphas, cv=5) \n",
    "elasticregr.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds_train = elasticregr.predict(X_train)\n",
    "Y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(elasticregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(elasticregr.score(X_train, Y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(elasticregr.score(X_test, Y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(Y_test, Y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(Y_test, Y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(Y_test, Y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((Y_test - Y_preds_test) / Y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all the regressions they all seem to be performing the same. The ElasticNet regression may be just slightly better than the other three. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
