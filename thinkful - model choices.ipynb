{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "\n",
    "Linear Regression. Linear regression is a simple and transparant way to predict continuous variables. I think there are probably a few variables that are highly correlated with running time and a lot that are not correlated. So a linear regression would be a good choice to just pick out the most important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. You have more features (columns) than rows in your dataset.\n",
    "\n",
    "Random Forest. Random forest is a highly accurate model that works well with many features. Since we have more features than observations I think the random forest would be the best option. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "\n",
    "Decision Tree. Performing a decision tree should give you the most important feature right away (the one with the lowest entropy) as that will be the first node of the tree. Your outcome will be a binary classifier of being jailed or not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "\n",
    "Naive Bayes. Naive bayes is a good model for text classification that is relatively easy to implement. One common use case of naive bayes is spam classification of emails and this would be a similar problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. You have 1000+ features.\n",
    "\n",
    "Random Forest. Again random forest models works well with many features and are highly accurate. Other models such as linear regression assume there is not multicolinearity between features, but with so many features in this dataset that may be unlikely. Gradient boosting would also be a good choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "\n",
    "KNN. I think a KNN model would make the most sense here because we can use the information from similar individuals and their decision as to whether they purchase or not and apply that to our test set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Your dataset dimensions are 982400 x 500\n",
    "\n",
    "Naive Bayes or Linear Regression. Because this is such a large dataset, I feel a simpler model would be better to start off with. Depending on what you are trying to predict, whether it is a classification or regression problem, I think a naive bayes model or linear regression would be best to start off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Identify faces in an image.\n",
    "\n",
    "Support Vector Machine. SVMs can be used to classify multiple classes so this would be a good case for this. You could train it on images of the faces you want to identify and then it should be able to pick those faces out later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "\n",
    "Naive Bayes. This should simply give you the probability that any flavor of ice cream is a favorite and then you could group that by gender.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
